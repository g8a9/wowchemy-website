---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Contrastive Language-Image Pre-training for the Italian Language
subtitle: ''
summary: ''
authors:
- Federico Bianchi
- Giuseppe Attanasio
- Raphael Pisoni
- Silvia Terragni
- Gabriele Sarti
- Sri Lakshmi
tags: []
categories: []
date: '2021-01-01'
lastmod: 2021-08-26T17:03:26+02:00
featured: true
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-08-26T15:03:17.807948Z'
publication_types:
- '1'
abstract: 'CLIP (Contrastive Language-Image Pre-training) is a very recent multi-modal model that jointly learns representations of images and texts. The model is trained on a massive amount of English data and shows impressive performance on zero-shot classification tasks. Training the same model on a different language is not trivial, since data in other languages might be not enough and the model needs high-quality translations of the texts to guarantee a good performance. In this paper, we present the first CLIP model for the Italian Language (CLIP-Italian), trained on more than 1.4 million image-text pairs. Results show that CLIP-Italian outperforms the multilingual CLIP model on the tasks of image retrieval and zero-shot classification.'
publication: '*arXiv preprint arXiv:2108.08688*'
url_pdf: 'https://arxiv.org/pdf/2108.08688.pdf'
---
