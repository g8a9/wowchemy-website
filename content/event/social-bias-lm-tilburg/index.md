---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "Social Biases in LMs: Why they are there, how do we measure and mitigate them"
event: "Guest Lecture at Tilburg University"
event_url:
location:
address:
  street:
  city:
  region:
  postcode:
  country:
summary:
abstract:

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: 2022-10-28T13:00:00+01:00
date_end: 2022-10-28T13:00:00+01:00
all_day: false

# Schedule page publish date (NOT event date).
publishDate: 2022-11-03T18:38:31+01:00

authors: []
tags: []

# Is this a featured event? (true/false)
featured: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

# Optional filename of your slides within your event's folder or a URL.
url_slides: seminar_tilburg_281022.pdf

url_code:
url_pdf:
url_video:

# Markdown Slides (optional).
#   Associate this event with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

In the blooming age of language technologies, the impact of social biases encoded in our models has surged to unprecedented levels. In this half-talk, half-discussion, we go through fundamental definitions of social bias in computer systems, specifically language models and social harm. We then review advances in measuring bias in NLP systems and discuss the frequently overlooked relation between intrinsic and extrinsic bias. We close our discussion with the relationship between lexical overfitting and bias and why it matters.